# Linear-Regression-parameters-sampling-distribution-
Demonstration of the difference between population and sample parameters using dummy data and sampling in Python

# Sampling Distribution of Parameters

This project demonstrates the difference between population parameters (which are constant) and estimated parameters (which are random variables) using a linear regression example.

## Purpose
The purpose of this project is to help understand the concept of **sampling distributions** and how **estimated parameters** vary depending on the data sample. While the population parameters are fixed and describe the entire population, the parameters estimated from samples change because they rely on specific data points in each sample. This variability is key in statistical inference and illustrates why we often talk about confidence intervals and uncertainty in parameter estimates.

By simulating data, taking random samples, and visualizing the resulting estimated parameters, this project aims to:
- Highlight the difference between true (population) parameters and sample-based estimates.
- Show that estimated parameters follow a **sampling distribution**, which captures the variability of estimates across different samples.
- Visualize how these estimates fluctuate around the true parameter values.

## Key Concept
- The **population parameters** (e.g., the true slope and intercept of the regression line) are fixed constants.
- The **estimated parameters** vary depending on the data sample. These estimates are random variables because they are based on the sample data, and different samples will yield different estimates.


